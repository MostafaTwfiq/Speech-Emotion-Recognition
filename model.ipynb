{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydrive.auth import GoogleAuth\n",
    "from pydrive.drive import GoogleDrive\n",
    "from google.colab import auth\n",
    "from oauth2client.client import GoogleCredentials\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa         #library for analyzing audio and music\n",
    "import librosa.display\n",
    "from IPython.display import Audio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Download the Dataset and Understand the Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auth.authenticate_user()\n",
    "gauth = GoogleAuth()\n",
    "gauth.credentials = GoogleCredentials.get_application_default()\n",
    "google_drive = GoogleDrive(gauth)\n",
    "downloaded = google_drive.CreateFile({'id':\"1v4zSFOdfbFyMFalPVB95M0atJDryKRYb\"})\n",
    "downloaded.GetContentFile('Crema.zip')        \n",
    "!unzip -qq /content/Crema.zip -d /content/dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/content/dataset/Crema/\"\n",
    "crema_directory = os.listdir(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotions = []\n",
    "file_path = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in crema_directory:\n",
    "  file_path.append(path + file)\n",
    "  emotion = file.split('_')\n",
    "  if emotion[2] == 'SAD':\n",
    "      emotions.append('sad')\n",
    "  elif emotion[2] == 'ANG':\n",
    "      emotions.append('angry')\n",
    "  elif emotion[2] == 'DIS':\n",
    "      emotions.append('disgust')\n",
    "  elif emotion[2] == 'FEA':\n",
    "      emotions.append('fear')\n",
    "  elif emotion[2] == 'HAP':\n",
    "      emotions.append('happy')\n",
    "  elif emotion[2] == 'NEU':\n",
    "      emotions.append('neutral')\n",
    "  else:\n",
    "      emotions.append('unknown emotion')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Emotions_df = pd.DataFrame(emotions, columns=['Emotion'])\n",
    "path_df = pd.DataFrame(file_path, columns=['Path'])\n",
    "Crema_df = pd.concat([path_df, Emotions_df], axis=1)\n",
    "Crema_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_waveform(data, sampling_rate, emotion):\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.title('Waveplot for {} emotion'.format(emotion.upper()), size=15)\n",
    "    librosa.display.waveplot(data, sr=sampling_rate)\n",
    "    plt.show()\n",
    "def spectrogram(data, sampling_rate, emotion):\n",
    "    X = librosa.stft(data)                      # stft function converts the data into short term fourier transform, we're working in frequency domain\n",
    "    Xdb = librosa.amplitude_to_db(abs(X))\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    plt.title('Spectrogram for  {} emotion'.format(emotion.upper()), size=15)\n",
    "    p=librosa.display.specshow(Xdb, sr=sampling_rate, x_axis='time', y_axis='hz')   \n",
    "    plt.colorbar()\n",
    "    return p\n",
    "def load_audio(path):\n",
    "  data, sampling_rate = librosa.load(path)\n",
    "  plot_waveform(data, sampling_rate, emotion)\n",
    "  p=spectrogram(data, sampling_rate, emotion)\n",
    "  print(f'Sampling rate: {sampling_rate}')\n",
    "  display(Audio(path))\n",
    "  return p   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotions = ['sad', 'angry', 'disgust', 'fear', 'happy', 'neutral']\n",
    "for emotion in emotions:\n",
    "  path = np.array(Crema_df.Path[Crema_df.Emotion==emotion])[0]\n",
    "  p=load_audio(path)\n",
    "  print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Create the Feature Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Building the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Big Picture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "384275cc682b8282d78d926a1c30ea86f5d409f6a82816c5f6672e2be770768b"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
